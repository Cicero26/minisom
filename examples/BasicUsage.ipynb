{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will see the basics of how to use MiniSom.\n",
    "\n",
    "Let's start importing MiniSom:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minisom import MiniSom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MiniSom relies on the Python ecosystem to import and preprocess the data. For this example we will load the <a href=\"https://archive.ics.uci.edu/ml/datasets/seeds\">seeds</a> dataset dataset using pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "columns=['area', 'perimeter', 'compactness', 'length_kernel', 'width_kernel',\n",
    "                   'asymmetry_coefficient', 'length_kernel_groove', 'target']\n",
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/00236/seeds_dataset.txt', \n",
    "                    names=columns, \n",
    "                   sep='\\t+', engine='python')\n",
    "target = data['target'].values\n",
    "label_names = {1:'Kama', 2:'Rosa', 3:'Canadian'}\n",
    "data = data[data.columns[:-1]]\n",
    "# data normalization\n",
    "data = (data - np.mean(data, axis=0)) / np.std(data, axis=0)\n",
    "data = data.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can initialize and train MiniSom as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization and training\n",
    "n_neurons = 9\n",
    "m_neurons = 9\n",
    "som = MiniSom(n_neurons, m_neurons, data.shape[1], sigma=1.5, learning_rate=.5, \n",
    "              neighborhood_function='gaussian', random_seed=0)\n",
    "\n",
    "som.pca_weights_init(data)\n",
    "som.train(data, 1000, verbose=True)  # random training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the result of the training we can plot the distance map (U-Matrix) using a pseudocolor where the neurons of the maps are displayed as an array of cells and the color represents the (weights) distance from the neighbour neurons. On top of the pseudo color we can add markers that repesent the samples mapped in the specific cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(9, 9))\n",
    "\n",
    "plt.pcolor(som.distance_map().T, cmap='bone_r')  # plotting the distance map as background\n",
    "plt.colorbar()\n",
    "\n",
    "# Plotting the response for each pattern in the iris dataset\n",
    "# different colors and markers for each label\n",
    "markers = ['o', 's', 'D']\n",
    "colors = ['C0', 'C1', 'C2']\n",
    "for cnt, xx in enumerate(data):\n",
    "    w = som.winner(xx)  # getting the winner\n",
    "    # palce a marker on the winning position for the sample xx\n",
    "    plt.plot(w[0]+.5, w[1]+.5, markers[target[cnt]-1], markerfacecolor='None',\n",
    "             markeredgecolor=colors[target[cnt]-1], markersize=12, markeredgewidth=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have an overview of how the samples are distributed across the map a scatter chart can be used where each dot represents the coordinates of the winning neuron. A random offset is added to avoid overlaps between points within the same cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_x, w_y = zip(*[som.winner(d) for d in data])\n",
    "w_x = np.array(w_x)\n",
    "w_y = np.array(w_y)\n",
    "\n",
    "plt.figure(figsize=(10, 9))\n",
    "plt.pcolor(som.distance_map().T, cmap='bone_r', alpha=.2)\n",
    "plt.colorbar()\n",
    "\n",
    "for c in np.unique(target):\n",
    "    idx_target = target==c\n",
    "    plt.scatter(w_x[idx_target]+.5+(np.random.rand(np.sum(idx_target))-.5)*.8,\n",
    "                w_y[idx_target]+.5+(np.random.rand(np.sum(idx_target))-.5)*.8, \n",
    "                s=50, c=colors[c-1], label=label_names[c])\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.savefig('resulting_images/som_seed.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have an idea of which neurons of the map are activated more often we can create another pseudocolor plot that reflects the activation frequencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "frequencies = som.activation_response(data)\n",
    "plt.pcolor(frequencies.T, cmap='Blues') \n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wehn dealing with a supervised problem, one can visualize the proportion of samples per class falling in a specific neuron using a pie chart per neuron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "labels_map = som.labels_map(data, [label_names[t] for t in target])\n",
    "\n",
    "fig = plt.figure(figsize=(9, 9))\n",
    "the_grid = gridspec.GridSpec(n_neurons, m_neurons, fig)\n",
    "for position in labels_map.keys():\n",
    "    label_fracs = [labels_map[position][l] for l in label_names.values()]\n",
    "    plt.subplot(the_grid[n_neurons-1-position[1],\n",
    "                         position[0]], aspect=1)\n",
    "    patches, texts = plt.pie(label_fracs)\n",
    "\n",
    "plt.legend(patches, label_names.values(), bbox_to_anchor=(3.5, 6.5), ncol=3)\n",
    "plt.savefig('resulting_images/som_seed_pies.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "win_map = som.win_map(data)\n",
    "size=som.distance_map().shape[0]\n",
    "qualities=np.zeros((size,size))\n",
    "for position, values in win_map.items():\n",
    "    qualities[position[0], position[1]] = np.mean(abs(values-som.get_weights()[position[0], position[1]]))\n",
    "\n",
    "layout = go.Layout(title='qualities')\n",
    "fig = go.Figure(layout=layout)\n",
    "fig.add_trace(go.Heatmap(z=qualities, colorscale='Viridis'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import math\n",
    "def showPropertyPlot(som, data, columns):\n",
    "# plots the distances for each different property\n",
    "    win_map = som.win_map(data)\n",
    "    size=som.distance_map().shape[0]\n",
    "    properties=np.zeros((size*size,2+data.shape[1]))\n",
    "    i=0\n",
    "    #A = np.array(size*size)\n",
    "    for row in range(0,size):\n",
    "        for col in range(0,size):\n",
    "            #print(len(values))\n",
    "            properties[size*row+col,0]=row\n",
    "            properties[size*row+col,1]=col\n",
    "\n",
    "    for position, values in win_map.items():\n",
    "        #print(len(values))\n",
    "        properties[size*position[0]+position[1],0]=position[0]\n",
    "        properties[size*position[0]+position[1],1]=position[1]\n",
    "        properties[size*position[0]+position[1],2:] = np.mean(values, axis=0)\n",
    "        #print(np.mean(values, axis=0))\n",
    "        i=i+1\n",
    "\n",
    "    B = ['row', 'col']\n",
    "    B.extend(columns)\n",
    "    properties = pd.DataFrame(data=properties, columns=B)\n",
    "    #properties=properties.sort_values(by=['row', 'col'])\n",
    "    #properties\n",
    "    \n",
    "    fig = make_subplots(rows=math.ceil(math.sqrt(data.shape[1])), cols=math.ceil(math.sqrt(data.shape[1])), shared_xaxes=False, horizontal_spacing=0.1, vertical_spacing=0.05, subplot_titles=columns, column_widths=None, row_heights=None)\n",
    "    i=0\n",
    "    zmin=min(np.min(properties.iloc[:,2:]))\n",
    "    zmax=max(np.max(properties.iloc[:,2:]))\n",
    "    for property in columns:\n",
    "        fig.add_traces(\n",
    "            [go.Heatmap(z=properties.sort_values(by=['row', 'col'])[property].values.reshape(size,size), zmax=zmax, zmin=zmin, coloraxis = 'coloraxis2')],\n",
    "            rows=[i // math.ceil(math.sqrt(data.shape[1])) + 1 ],\n",
    "            cols=[i % math.ceil(math.sqrt(data.shape[1])) + 1 ]\n",
    "            )\n",
    "        i=i+1\n",
    "\n",
    "    for layout in fig.layout:\n",
    "        #print(layout)\n",
    "        if layout.startswith('xaxis') or layout.startswith('yaxis'):\n",
    "            fig.layout[layout].visible=False\n",
    "            fig.layout[layout].visible=False\n",
    "        if layout.startswith('coloraxis'):\n",
    "            fig.layout[layout].cmax=zmax\n",
    "            fig.layout[layout].cmin=zmin   \n",
    "            #fig.layout[layout].colorscale='Rainbow'\n",
    "        if layout.startswith('colorscale'):        \n",
    "            #print(fig.layout[layout])\n",
    "            fig.layout[layout]={'diverging':'viridis'}\n",
    "\n",
    "    fig.update_layout(\n",
    "        #width=800,\n",
    "        height=800\n",
    "    )\n",
    "    fig.show()\n",
    "    \n",
    "showPropertyPlot(som, data, columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distributionMap(data, clusters, size, columns, minimum, maximum, plottype='barpolar'):\n",
    "    spec={\"type\": \"polar\"}\n",
    "    fig = make_subplots(rows=size, cols=size, specs=np.full((size,size),spec).tolist(), shared_yaxes=True, shared_xaxes=True,horizontal_spacing=0, vertical_spacing=0, subplot_titles=None, column_widths=None, row_heights=None)\n",
    "    categories=columns\n",
    "    if plottype=='spider':\n",
    "        for index, row in data.iterrows():\n",
    "            fig.add_traces(\n",
    "                [go.Scatterpolargl(\n",
    "                    r=row['max'],\n",
    "                    name='max',\n",
    "                    fillcolor='darkgray',\n",
    "                    line=dict(color='darkgray'),\n",
    "                    theta=categories,           \n",
    "                    opacity=0.5),\n",
    "                go.Scatterpolargl(\n",
    "                    r=row['mean'],\n",
    "                    name='mean',\n",
    "                    fillcolor='blue',\n",
    "                    line=dict(color='blue'),\n",
    "                    theta=categories,           \n",
    "                    opacity=0.5),\n",
    "                go.Scatterpolargl(\n",
    "                    r=row['min'],\n",
    "                    name='min',\n",
    "                    fillcolor='red',\n",
    "                    line=dict(color='red'),\n",
    "                    theta=categories,           \n",
    "                    opacity=0.5)],\n",
    "                rows=[row['row'], row['row'], row['row']],\n",
    "                cols=[row['col'], row['col'], row['col']]\n",
    "                )\n",
    "    else:\n",
    "        for index, row in data.iterrows():\n",
    "            fig.add_traces(\n",
    "                [\n",
    "                go.Barpolar(                   \n",
    "                    base=minimum-1,\n",
    "                    r=row['max']-minimum-1,\n",
    "                    name='max'+str(index),\n",
    "                    marker_color=\"darkgray\",\n",
    "                    theta=categories,           \n",
    "                    #opacity=1\n",
    "                 ),\n",
    "                go.Barpolar(           \n",
    "                    base=minimum-1,\n",
    "                    r=row['mean']-minimum-1,\n",
    "                    name='mean'+str(index),\n",
    "                    marker_color=\"blue\",\n",
    "                    theta=categories,           \n",
    "                    #opacity=1\n",
    "                 ),\n",
    "                go.Barpolar(           \n",
    "                    base=minimum-1,\n",
    "                    r=row['min']-minimum-1,\n",
    "                    name='min'+str(index),\n",
    "                    marker_color=\"darkred\",\n",
    "                    theta=categories,           \n",
    "                    #opacity=1\n",
    "                ) \n",
    "                ],\n",
    "                rows=[row['row'], row['row'], row['row']],\n",
    "                cols=[row['col'], row['col'], row['col']]\n",
    "                )        \n",
    "\n",
    "    if plottype=='spider':\n",
    "        fig.update_traces(mode='lines', fill='toself')\n",
    "    for layout in fig.layout:\n",
    "        if layout.startswith('polar'):\n",
    "            fig.layout[layout].angularaxis.visible=False\n",
    "            fig.layout[layout].angularaxis.tickfont.size = 7\n",
    "            fig.layout[layout].radialaxis.visible=True\n",
    "            fig.layout[layout].radialaxis.tickfont.size = 10\n",
    "            fig.layout[layout].barmode='overlay'\n",
    "            fig.layout[layout].radialaxis.range = [minimum, maximum+1]\n",
    "\n",
    "    fig.update_layout(\n",
    "        width=900,\n",
    "        height=900,\n",
    "        font_size=9,\n",
    "        showlegend=False\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotDistributionOfDataInClusters(som, data, columns, plottype='barpolar'): \n",
    "    size=som.distance_map().shape[0]\n",
    "    clusters=res = np.array(np.arange(0,size*size)).reshape(size,size)\n",
    "    distributionMapData=pd.DataFrame(columns=['col', 'row', 'min', 'mean', 'max'])\n",
    "    win_map=som.win_map(data)\n",
    "    for position in win_map.keys():\n",
    "        winner=win_map[position]\n",
    "        minima=np.min(winner, axis=0)\n",
    "        means=np.mean(winner, axis=0)\n",
    "        maxima=np.max(winner, axis=0)\n",
    "        row=int(position[0]+1)\n",
    "        col=int(position[1]+1)\n",
    "        distributionMapData=distributionMapData.append(\n",
    "            {'col': col,\n",
    "             # row needs to be shifted because all the other plots (heatmaps) are shown with row 0 at bottom \n",
    "             'row': size-row+1, \n",
    "             'min': minima, \n",
    "             'mean': means, \n",
    "             'max': maxima}, verify_integrity=True, ignore_index=True)\n",
    "\n",
    "    noClusters=np.max(clusters).item()+1\n",
    "    clusterData=pd.DataFrame(columns=['col', 'row', 'min', 'mean', 'max'])\n",
    "    minimum=0\n",
    "    maximum=0\n",
    "    for cluster in range(0, noClusters):    \n",
    "        listOfCluster=distributionMapData[distributionMapData.apply(lambda x: clusters[x.row-1,x.col-1] == cluster, axis=1)]\n",
    "        if (listOfCluster.size>0):\n",
    "            minima=listOfCluster['min'].values[0]\n",
    "            for val in listOfCluster['min'].values:\n",
    "                minima = np.minimum(val, minima) \n",
    "\n",
    "            maxima=listOfCluster['max'].values[0]\n",
    "            for val in listOfCluster['max'].values:\n",
    "                maxima = np.maximum(val, maxima) \n",
    "\n",
    "            flat_list = []\n",
    "            for sublist in listOfCluster['mean'].values:\n",
    "                flat_list.append(sublist.tolist())\n",
    "                means = np.mean(flat_list, axis=0) \n",
    "        clusterData=clusterData.append(\n",
    "            {'col': cluster-size*(cluster//9)+1,\n",
    "             # row needs to be switched because all the other plots (heatmaps) are shown with row 0 at bottom \n",
    "             'row': (cluster)//9+1, \n",
    "             'min': minima, \n",
    "             'mean': means, \n",
    "             'max': maxima}, verify_integrity=True, ignore_index=True)\n",
    "        minimum=min(minimum,np.min(minima))\n",
    "        maximum=max(maximum,np.min(maxima))\n",
    "\n",
    "    distributionMap(clusterData, clusters, size, columns, minimum, maximum, plottype)\n",
    "\n",
    "plotDistributionOfDataInClusters(som, data, columns[:-1], plottype='barpolar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Hamel, Brown: Improved Interpretability of the Unified Distance Matrix with Connected Components\n",
    "## Starburst Gradient visualization\n",
    "At the core of the implementation is the function find.internal.node which, given the map coordinates of a neural element, will find the corresponding internal node of the associated star. Table I shows the pseudo code for this function. Given a position on the map this function first searches the adjacent nodes for the minimal UMAT value using the function find.min. If an adjacent node with a smaller UMAT value than the value of our current node exists and if this UMAT value is smaller than the UMAT values of all other adjacent nodes, then that node lies along the maximum gradient of the surface and we make this node our new current position. If no such node exists, then the gradient at our current position is zero and we are at an internal node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findMin(x, y, umat):\n",
    "    newxmin=max(0,x-1)\n",
    "    newxmax=min(umat.shape[0],x+2)\n",
    "    newymin=max(0,y-1)\n",
    "    newymax=min(umat.shape[1],y+2)\n",
    "    minx, miny = np.where(umat[newxmin:newxmax,newymin:newymax] == umat[newxmin:newxmax,newymin:newymax].min())\n",
    "    return newxmin+minx[0], newymin+miny[0]\n",
    "\n",
    "def findInternalNode(x, y, umat):\n",
    "    minx, miny = findMin(x,y,umat)\n",
    "    if (minx == x and miny == y):\n",
    "        cx = minx\n",
    "        cy = miny\n",
    "    else:\n",
    "        cx,cy = findInternalNode(minx,miny,umat)\n",
    "    return cx, cy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotStarburstMap(som):\n",
    "    layout = go.Layout(title='starburstMap')\n",
    "    fig = go.Figure(layout=layout)\n",
    "    fig.add_trace(go.Heatmap(z=som.distance_map()))\n",
    "    shapes=[]\n",
    "\n",
    "    for row in np.arange(som.distance_map().shape[0]):\n",
    "        for col in np.arange(som.distance_map().shape[1]):\n",
    "            cx,cy = findInternalNode(row, col, som.distance_map())\n",
    "            shape=go.layout.Shape(\n",
    "                    type=\"line\",\n",
    "                    x0=col,\n",
    "                    y0=row,\n",
    "                    x1=cy,\n",
    "                    y1=cx,\n",
    "                    line=dict(\n",
    "                        color=\"Black\",\n",
    "                        width=1\n",
    "                    )\n",
    "                )\n",
    "            shapes=np.append(shapes, shape)\n",
    "\n",
    "    fig.update_layout(shapes=shapes.tolist()) \n",
    "    fig.show()\n",
    "    \n",
    "plotStarburstMap(som)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand how the training evolves we can plot the quantization and topographic error of the SOM at each step. This is particularly important when estimating the number of iterations to run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "som = MiniSom(10, 20, data.shape[1], sigma=3., learning_rate=.7,\n",
    "              neighborhood_function='gaussian', random_seed=10)\n",
    "\n",
    "max_iter = 1000\n",
    "q_error = []\n",
    "t_error = []\n",
    "\n",
    "for i in range(max_iter):\n",
    "    rand_i = np.random.randint(len(data))\n",
    "    som.update(data[rand_i], som.winner(data[rand_i]), i, max_iter)\n",
    "    q_error.append(som.quantization_error(data))\n",
    "    t_error.append(som.topographic_error(data))\n",
    "\n",
    "plt.plot(np.arange(max_iter), q_error, label='quantization error')\n",
    "plt.plot(np.arange(max_iter), t_error, label='topographic error')\n",
    "plt.ylabel('quantization error')\n",
    "plt.xlabel('iteration index')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that in the snippet above weto run each learning iteration in a for loop and saved the errors in separated lists."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
